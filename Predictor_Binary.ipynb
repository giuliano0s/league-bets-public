{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07ebcb47",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed29b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "import json\n",
    "\n",
    "from Utils.constants import *\n",
    "from Utils.utils_file import Utils_Class\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36bef382",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d199165f",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c267291",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Score'\n",
    "split_type = 0\n",
    "default_model = 7\n",
    "\n",
    "Utils = Utils_Class(target=target,\n",
    "                    split_type=split_type,\n",
    "                    default_model=default_model)\n",
    "\n",
    "Utils.TARGET_DF = Utils.TARGET_DF[(Utils.TARGET_DF[Utils.TARGET]!=2)\n",
    "                                  & (Utils.TARGET_DF['realSemesterYear'].astype(int)<=int(Utils.CURRENT_SEMESTER_YEAR))]\n",
    "\n",
    "regions_to_feed, regions_to_predict = Utils.region_lists(min_entries=30)\n",
    "Utils.define_models('binary')\n",
    "\n",
    "#regions_to_predict.remove('MSI')\n",
    "#regions_to_predict.remove('World')\n",
    "regions_to_predict = regions_to_predict[:5]\n",
    "#regions_to_predict = ['MSI','World']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfa4dfa9",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5291e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "regions_stats = pd.DataFrame(columns=['region','model','size'])\n",
    "regions_stats['region'] = regions_to_predict\n",
    "regions_list = regions_stats['region']\n",
    "regions_stats['model'] = Utils.DEFAULT_MODEL\n",
    "\n",
    "regions_train_data = dict(zip(regions_list,regions_list.apply(lambda x: [x])))\n",
    "regions_stats['accuracy_0'] = np.nan\n",
    "regions_stats['accuracy_1'] = np.nan\n",
    "regions_stats['accuracy_2'] = np.nan\n",
    "regions_stats['cut_off_var'] = 1.5\n",
    "\n",
    "regions_feature_cols = dict(zip(regions_list,[0]*len(regions_list)))\n",
    "for key in regions_feature_cols:\n",
    "    regions_feature_cols[key] = TEAM_SIMPLE_FEATURE_COLS.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a78da8e3",
   "metadata": {},
   "source": [
    "### TRAIN DATA SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c23655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LPL -> nan:\n",
      "\n",
      "0.331 -> VCS added                                           \n",
      "0.328 -> LCS added                                           \n",
      "0.322 -> OPL added                                           \n",
      "0.313 -> LCO added                                           \n",
      "0.307 -> LCK added                                           \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m nn,regionToTest \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(regionsToTest):\n\u001b[0;32m     18\u001b[0m     regions_train_data[region]\u001b[39m.\u001b[39mappend(regionToTest)\n\u001b[1;32m---> 20\u001b[0m     metric, pred \u001b[39m=\u001b[39m Utils\u001b[39m.\u001b[39;49mgenerate_metric(region_model_number, regions_feature_cols[region]\n\u001b[0;32m     21\u001b[0m                                          , regions_train_data[region], tempTournamentId, reps\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m metric \u001b[39m<\u001b[39m regionFinalAcc \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39misnan(regionFinalAcc):\n\u001b[0;32m     24\u001b[0m         regionFinalAcc \u001b[39m=\u001b[39m metric\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\utils\\utils_file.py:176\u001b[0m, in \u001b[0;36mUtils_Class.generate_metric\u001b[1;34m(self, model_number, region_feature_cols, region_data_list, tournament_id, reps)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(reps):\n\u001b[0;32m    175\u001b[0m     region_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mBASE_MODELS[model_number]\n\u001b[1;32m--> 176\u001b[0m     region_model\u001b[39m.\u001b[39;49mfit(xtrain, ytrain)\n\u001b[0;32m    177\u001b[0m     pred \u001b[39m=\u001b[39m region_model\u001b[39m.\u001b[39mpredict(xtest)\n\u001b[0;32m    178\u001b[0m     errors \u001b[39m=\u001b[39m accuracy_score(ytest, pred)\u001b[39m+\u001b[39merrors\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[0;32m   1292\u001b[0m     path_func(\n\u001b[0;32m   1293\u001b[0m         X,\n\u001b[0;32m   1294\u001b[0m         y,\n\u001b[0;32m   1295\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1296\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1297\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1298\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1299\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1300\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1301\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1302\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1303\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1304\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1305\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1306\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1307\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1308\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1309\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1310\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1311\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m   1312\u001b[0m     )\n\u001b[0;32m   1313\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1314\u001b[0m )\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:468\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    466\u001b[0m     l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C\n\u001b[0;32m    467\u001b[0m     args \u001b[39m=\u001b[39m (X, target, sample_weight, l2_reg_strength, n_threads)\n\u001b[1;32m--> 468\u001b[0m     w0, n_iter_i \u001b[39m=\u001b[39m _newton_cg(\n\u001b[0;32m    469\u001b[0m         hess, func, grad, w0, args\u001b[39m=\u001b[39;49margs, maxiter\u001b[39m=\u001b[39;49mmax_iter, tol\u001b[39m=\u001b[39;49mtol\n\u001b[0;32m    470\u001b[0m     )\n\u001b[0;32m    471\u001b[0m \u001b[39melif\u001b[39;00m solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnewton-cholesky\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m     \u001b[39m# The division by sw_sum is a consequence of the rescaling of\u001b[39;00m\n\u001b[0;32m    473\u001b[0m     \u001b[39m# sample_weight, see comment above.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C \u001b[39m/\u001b[39m sw_sum\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\sklearn\\utils\\optimize.py:193\u001b[0m, in \u001b[0;36m_newton_cg\u001b[1;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[0;32m    189\u001b[0m termcond \u001b[39m=\u001b[39m eta \u001b[39m*\u001b[39m maggrad\n\u001b[0;32m    191\u001b[0m \u001b[39m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[39m# avoid inverting the Hessian\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m xsupi \u001b[39m=\u001b[39m _cg(fhess_p, fgrad, maxiter\u001b[39m=\u001b[39;49mmaxinner, tol\u001b[39m=\u001b[39;49mtermcond)\n\u001b[0;32m    195\u001b[0m alphak \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m line_search:\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\sklearn\\utils\\optimize.py:88\u001b[0m, in \u001b[0;36m_cg\u001b[1;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mabs(ri)) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tol:\n\u001b[0;32m     86\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m Ap \u001b[39m=\u001b[39m fhess_p(psupi)\n\u001b[0;32m     89\u001b[0m \u001b[39m# check curvature\u001b[39;00m\n\u001b[0;32m     90\u001b[0m curv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(psupi, Ap)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:585\u001b[0m, in \u001b[0;36mLinearModelLoss.gradient_hessian_product.<locals>.hessp\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    583\u001b[0m     ret[:n_features] \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m (hX \u001b[39m@\u001b[39m s[:n_features])\n\u001b[0;32m    584\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     ret[:n_features] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mmulti_dot([X\u001b[39m.\u001b[39;49mT, hX, s[:n_features]])\n\u001b[0;32m    586\u001b[0m ret[:n_features] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m l2_reg_strength \u001b[39m*\u001b[39m s[:n_features]\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept:\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmulti_dot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\numpy\\linalg\\linalg.py:2709\u001b[0m, in \u001b[0;36mmulti_dot\u001b[1;34m(arrays, out)\u001b[0m\n\u001b[0;32m   2707\u001b[0m \u001b[39m# _multi_dot_three is much faster than _multi_dot_matrix_chain_order\u001b[39;00m\n\u001b[0;32m   2708\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m-> 2709\u001b[0m     result \u001b[39m=\u001b[39m _multi_dot_three(arrays[\u001b[39m0\u001b[39;49m], arrays[\u001b[39m1\u001b[39;49m], arrays[\u001b[39m2\u001b[39;49m], out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m   2710\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2711\u001b[0m     order \u001b[39m=\u001b[39m _multi_dot_matrix_chain_order(arrays)\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\Jupyter\\Personal\\league-bets\\.venv\\lib\\site-packages\\numpy\\linalg\\linalg.py:2741\u001b[0m, in \u001b[0;36m_multi_dot_three\u001b[1;34m(A, B, C, out)\u001b[0m\n\u001b[0;32m   2739\u001b[0m     \u001b[39mreturn\u001b[39;00m dot(dot(A, B), C, out\u001b[39m=\u001b[39mout)\n\u001b[0;32m   2740\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2741\u001b[0m     \u001b[39mreturn\u001b[39;00m dot(A, dot(B, C), out\u001b[39m=\u001b[39mout)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regions_train_data = dict(zip(regions_list,regions_list.apply(lambda x: [x])))\n",
    "regions_stats['accuracy_0'] = np.nan\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regions_stats['accuracy_0'][n]\n",
    "    tempTournamentId = region + Utils.CURRENT_SEMESTER_YEAR\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    region_model_number = regions_stats['model'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    \n",
    "    regionsToTest = [x for x in regions_to_feed]\n",
    "    regionsToTest.remove(region)\n",
    "    random.shuffle(regionsToTest)\n",
    "    for nn,regionToTest in enumerate(regionsToTest):\n",
    "        regions_train_data[region].append(regionToTest)\n",
    "        \n",
    "        metric, pred = Utils.generate_metric(region_model_number, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], tempTournamentId, reps=5)\n",
    "        \n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            \n",
    "            print(f'{regionFinalAcc} -> {regionToTest} added                                           ')\n",
    "        else:\n",
    "            regions_train_data[region].remove(regionToTest)\n",
    "    \n",
    "    regions_stats['accuracy_0'][n] = regionFinalAcc\n",
    "    regions_stats['size'][n] = len(pred)\n",
    "    \n",
    "    print(f'\\n\\naccuracy: {regionFinalAcc}')\n",
    "    print(f'{region} train data: {regions_train_data[region]}\\nlen:{len(regions_train_data[region])}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "\n",
    "mean_acc = np.mean(regions_stats['accuracy_0'])\n",
    "print(mean_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35642234",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a9c57f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LPL -> 0.35:\n",
      "\n",
      "model: 7\n",
      "GPM removed for 0.316                                                \n",
      "GD@15 removed for 0.307                                                \n",
      "\n",
      "\n",
      "accuracy: 0.307\n",
      "LPL feature count: 20\n",
      "test data len: 329\n",
      "\n",
      "=========\n",
      "\n",
      "[2 of 5] region LCK -> 0.298:\n",
      "\n",
      "model: 7\n",
      "\n",
      "\n",
      "accuracy: 0.298\n",
      "LCK feature count: 22\n",
      "test data len: 248\n",
      "\n",
      "=========\n",
      "\n",
      "[3 of 5] region PCS -> 0.314:\n",
      "\n",
      "model: 7\n",
      "GPM removed for 0.305                                                \n",
      "\n",
      "\n",
      "accuracy: 0.305\n",
      "PCS feature count: 21\n",
      "test data len: 105\n",
      "\n",
      "=========\n",
      "\n",
      "[4 of 5] region VCS -> 0.283:\n",
      "\n",
      "model: 7\n",
      "DPM removed for 0.261                                                \n",
      "\n",
      "\n",
      "accuracy: 0.261\n",
      "VCS feature count: 21\n",
      "test data len: 92\n",
      "\n",
      "=========\n",
      "\n",
      "[5 of 5] region Ultraliga -> 0.296:\n",
      "\n",
      "model: 7\n",
      "\n",
      "\n",
      "accuracy: 0.296\n",
      "Ultraliga feature count: 22\n",
      "test data len: 108\n",
      "\n",
      "0.2934\n"
     ]
    }
   ],
   "source": [
    "regions_stats['accuracy_1'] = np.nan\n",
    "regions_feature_cols = dict(zip(regions_list,[0]*len(regions_list)))\n",
    "for key in regions_feature_cols:\n",
    "    regions_feature_cols[key] = TEAM_SIMPLE_FEATURE_COLS.copy()\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regions_stats['accuracy_0'][n]\n",
    "    tempTournamentId = region + Utils.CURRENT_SEMESTER_YEAR\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    region_model_number = regions_stats['model'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    print(f'model: {region_model_number}')\n",
    "    \n",
    "    initialFeatures = regions_feature_cols[region].copy()\n",
    "    for nn,feature in enumerate(initialFeatures):\n",
    "        regions_feature_cols[region].remove(feature)\n",
    "        \n",
    "        metric, pred = Utils.generate_metric(region_model_number, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], tempTournamentId, reps=5)\n",
    "        \n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            print(f'{feature} removed for {metric}                                                ')\n",
    "        else:\n",
    "            regions_feature_cols[region].append(feature)\n",
    "    \n",
    "    regions_stats['accuracy_1'][n] = regionFinalAcc\n",
    "    print(f'\\n\\naccuracy: {regionFinalAcc}')\n",
    "    print(f'{region} feature count: {len(regions_feature_cols[region])}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "    \n",
    "mean_acc = np.mean(regions_stats['accuracy_1'])\n",
    "print(mean_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c01c99",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd7a21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LPL -> 0.35:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.368\n",
      "model 1 -> 0.386\n",
      "model 2 -> 0.325\n",
      "model 3 -> 0.431\n",
      "model 4 -> 0.462\n",
      "model 5 -> 0.458\n",
      "model 6 -> 0.307\n",
      "model 7 -> 0.307\n",
      "\n",
      "accuracy: 0.307\n",
      "best model: 6\n",
      "\n",
      "=========\n",
      "\n",
      "[2 of 5] region LCK -> 0.298:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.333\n",
      "model 1 -> 0.464\n",
      "model 2 -> 0.327\n",
      "model 3 -> 0.35\n",
      "model 4 -> 0.347\n",
      "model 5 -> 0.395\n",
      "model 6 -> 0.306\n",
      "model 7 -> 0.298\n",
      "\n",
      "accuracy: 0.298\n",
      "best model: 7\n",
      "\n",
      "=========\n",
      "\n",
      "[3 of 5] region PCS -> 0.314:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.345\n",
      "model 1 -> 0.295\n",
      "model 2 -> 0.362\n",
      "model 3 -> 0.339\n",
      "model 4 -> 0.446\n",
      "model 5 -> 0.43\n",
      "model 6 -> 0.333\n",
      "model 7 -> 0.305\n",
      "\n",
      "accuracy: 0.295\n",
      "best model: 1\n",
      "\n",
      "=========\n",
      "\n",
      "[4 of 5] region VCS -> 0.283:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.38\n",
      "model 1 -> 0.467\n",
      "model 2 -> 0.391\n",
      "model 3 -> 0.407\n",
      "model 4 -> 0.337\n",
      "model 5 -> 0.504\n",
      "model 6 -> 0.293\n",
      "model 7 -> 0.261\n",
      "\n",
      "accuracy: 0.261\n",
      "best model: 7\n",
      "\n",
      "=========\n",
      "\n",
      "[5 of 5] region Ultraliga -> 0.296:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.35\n",
      "model 1 -> 0.426\n",
      "model 2 -> 0.306\n",
      "model 3 -> 0.367\n",
      "model 4 -> 0.417\n",
      "model 5 -> 0.42\n",
      "model 6 -> 0.306\n",
      "model 7 -> 0.296\n",
      "\n",
      "accuracy: 0.296\n",
      "best model: 7\n",
      "\n",
      "0.2914\n"
     ]
    }
   ],
   "source": [
    "regions_stats['accuracy_2'] = np.nan\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    currAcc = regions_stats['accuracy_0'][n]\n",
    "    currModel = regions_stats['model'][n]\n",
    "    tempTournamentId = region + Utils.CURRENT_SEMESTER_YEAR\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {currAcc}:\\n')\n",
    "    print(f'current model: {currModel}\\n')\n",
    "    \n",
    "    bestModelAbs = (regions_stats[regions_stats['region']==region])['accuracy_2'].iloc[0]\n",
    "    for model in range(len(Utils.BASE_MODELS)):\n",
    "        metric, pred = Utils.generate_metric(model, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], tempTournamentId, reps=5)\n",
    "        if metric < bestModelAbs or np.isnan(bestModelAbs):\n",
    "            bestModelAbs = metric\n",
    "            bestModel = model\n",
    "        print(f'model {model} -> {metric}')\n",
    "\n",
    "    regions_stats['model'][n] = bestModel\n",
    "    regions_stats['accuracy_2'][n] = bestModelAbs\n",
    "    \n",
    "    print(f'\\naccuracy: {bestModelAbs}')\n",
    "    print(f'best model: {bestModel}\\n')\n",
    "    \n",
    "mean_acc = np.mean(regions_stats['accuracy_2'])\n",
    "print(mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f194c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../Data/raw_data/regions_feature_cols.json', 'w') as fp:\n",
    "    json.dump(regions_feature_cols)\n",
    "with open(f'../Data/raw_data/regions_train_data.json', 'w') as fp:\n",
    "    json.dump(regions_train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87477a1d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92a6e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3082\n",
      "0.2934\n",
      "0.2914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>accuracy_0</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>cut_off_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LPL</td>\n",
       "      <td>6</td>\n",
       "      <td>329</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.307</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LCK</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.298</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCS</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.295</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCS</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.261</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultraliga</td>\n",
       "      <td>7</td>\n",
       "      <td>108</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.296</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region  model size  accuracy_0  accuracy_1  accuracy_2  cut_off_var\n",
       "0        LPL      6  329       0.350       0.307       0.307          1.5\n",
       "1        LCK      7  248       0.298       0.298       0.298          1.5\n",
       "2        PCS      1  105       0.314       0.305       0.295          1.5\n",
       "3        VCS      7   92       0.283       0.261       0.261          1.5\n",
       "4  Ultraliga      7  108       0.296       0.296       0.296          1.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(regions_stats['accuracy_0']))\n",
    "print(np.mean(regions_stats['accuracy_1']))\n",
    "print(np.mean(regions_stats['accuracy_2']))\n",
    "regions_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab7301bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_names(name):\n",
    "    tempDf = Utils.team_data_table[(Utils.team_data_table['Name']==name)\n",
    "                           & (Utils.team_data_table['Year'].astype(int)==Utils.CURRENT_YEAR)\n",
    "                           & (Utils.team_data_table['Semester'].astype(int)==Utils.CURRENT_SEMESTER)]\n",
    "    \n",
    "    namesList = tempDf[['TOP','JNG','MID','ADC','SUP']].iloc[0]\n",
    "    \n",
    "    return namesList\n",
    "\n",
    "def get_feature_team_mean(namesList,feature):\n",
    "    values=[]\n",
    "    noDataList=[]\n",
    "    for name in namesList:\n",
    "        filteredTempDf = Utils.player_data_table[(Utils.player_data_table['Player']==name)\n",
    "                                             & (Utils.player_data_table['Year']==Utils.CURRENT_YEAR)\n",
    "                                             & (Utils.player_data_table['Semester']==Utils.CURRENT_SEMESTER)]\n",
    "        \n",
    "        valueToAppend = filteredTempDf[feature.replace('Team_Red_','').replace('Team_Blue_','')]\n",
    "        if len(valueToAppend)>0:\n",
    "            values.append(valueToAppend.iloc[0])\n",
    "        else: \n",
    "            noDataList.append(name)\n",
    "    \n",
    "    return np.mean(values),noDataList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a04ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'CNB e-Sports Club',\n",
       " 1: 'FURIA Esports',\n",
       " 2: 'FURIA Uppercut',\n",
       " 3: 'Flamengo Los Grandes',\n",
       " 4: 'Flamengo eSports',\n",
       " 5: 'Fluxo',\n",
       " 6: 'INTZ e-Sports',\n",
       " 7: 'INTZ eSports',\n",
       " 8: 'KaBuM! e-Sports',\n",
       " 9: 'LOUD',\n",
       " 10: 'Liberty',\n",
       " 11: 'Los Grandes',\n",
       " 12: 'Netshoes Miners',\n",
       " 13: 'Prodigy Esports',\n",
       " 14: 'RED Canids',\n",
       " 15: 'Redemption POA',\n",
       " 16: 'Rensga eSports',\n",
       " 17: 'Santos e-Sports',\n",
       " 18: 'Team oNe eSports',\n",
       " 19: 'Uppercut eSports',\n",
       " 20: 'Vivo Keyd',\n",
       " 21: 'Vivo Keyd Stars',\n",
       " 22: 'Vorax Liberty',\n",
       " 23: 'paiN Gaming'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regionTest = 'CBLOL'\n",
    "dfTemp = Utils.TARGET_DF[Utils.TARGET_DF['regionAbrev']==regionTest]\n",
    "teamsSet = sorted(set(list(dfTemp['Blue'].unique())+list(dfTemp['Red'].unique())))\n",
    "teamsDict = dict(zip(range(len(teamsSet)),teamsSet))\n",
    "teamsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b14490bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teamBlueNames = ['fNb', 'Goot', 'Envy', 'Netuno', 'RedBert']\n",
      "teamRedNames = ['Kiari', 'Disamis', 'Krastyel', 'Cavalo', 'Matsukaze']\n"
     ]
    }
   ],
   "source": [
    "team0 = 1\n",
    "team1 = 10\n",
    "\n",
    "playerNames = Utils.team_data_table[(Utils.team_data_table['Name']==teamsDict[team0])\n",
    "                            & (Utils.team_data_table['Year'].astype(int)==Utils.CURRENT_YEAR)\n",
    "                            & (Utils.team_data_table['Semester'].astype(int)==Utils.CURRENT_SEMESTER)][['TOP','JNG','MID','ADC','SUP']]\n",
    "\n",
    "try: print(f'teamBlueNames = {list(playerNames.values[0])}')\n",
    "except: print('no team found')\n",
    "\n",
    "playerNames = Utils.team_data_table[(Utils.team_data_table['Name']==teamsDict[team1])\n",
    "                            & (Utils.team_data_table['Year'].astype(int)==Utils.CURRENT_YEAR)\n",
    "                            & (Utils.team_data_table['Semester'].astype(int)==Utils.CURRENT_SEMESTER)][['TOP','JNG','MID','ADC','SUP']]\n",
    "\n",
    "try:print(f'teamRedNames = {list(playerNames.values[0])}')\n",
    "except: print('no team found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59059b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n"
     ]
    }
   ],
   "source": [
    "manualNameInsert = 1\n",
    "\n",
    "for i in range(5):\n",
    "    print('=================')\n",
    "    for swap in [0,1]:\n",
    "        #teams\n",
    "        teamBlueNames = ['fNb', 'Goot', 'Envy', 'Trigo', 'RedBert']\n",
    "        teamRedNames = ['Kiari', 'accez', 'Piloto', 'Juliera', 'Cavalo']\n",
    "        teamBlueTest = teamsDict[team0]\n",
    "        teamRedTest = teamsDict[team1]\n",
    "        if swap==1:\n",
    "                teamTemp = teamBlueTest\n",
    "                teamBlueTest = teamRedTest\n",
    "                teamRedTest = teamTemp\n",
    "\n",
    "                teamNamesTemp = teamBlueNames\n",
    "                teamBlueNames = teamRedNames\n",
    "                teamRedNames = teamNamesTemp\n",
    "\n",
    "        #generate train data\n",
    "        finalDfInput = Utils.TARGET_DF[Utils.TARGET_DF['regionAbrev'].isin(regions_train_data[regionTest])].copy()\n",
    "        finalDfInput = finalDfInput.sort_values(by='Date',ascending=True)\n",
    "        for col in finalDfInput.columns:\n",
    "                    finalDfInput[col].fillna(0,inplace=True)\n",
    "\n",
    "        featureColsFiltered = [x for x in list(finalDfInput.columns) \n",
    "                               if x.replace('Team_Blue_','').replace('Team_Red_','') in regions_feature_cols[regionTest]]\n",
    "        \n",
    "        xdata= finalDfInput[featureColsFiltered]\n",
    "        ydata = finalDfInput[Utils.TARGET]\n",
    "\n",
    "        #generate features to predict\n",
    "        if manualNameInsert==0:\n",
    "            teamBlueNames = get_team_names(teamBlueTest)\n",
    "            teamRedNames = get_team_names(teamRedTest)\n",
    "\n",
    "        inputFeatures = Utils.TARGET_DF.drop([Utils.TARGET+'Data']+OFF_COLS,axis=1,errors='ignore').columns\n",
    "        featuresDict = {}\n",
    "        for feature in featureColsFiltered:\n",
    "            side = feature.split('_')[1]\n",
    "            if side == 'Blue':\n",
    "                featuresDict[feature],noDataNames = get_feature_team_mean(teamBlueNames,feature)\n",
    "                \n",
    "            elif side == 'Red':\n",
    "                featuresDict[feature],noDataNames = get_feature_team_mean(teamRedNames,feature)\n",
    "        print(f'no data names on: {noDataNames}')\n",
    "\n",
    "        inputDf = pd.DataFrame(featuresDict.values(),index=featuresDict.keys()).transpose()\n",
    "        for col in inputDf.columns:\n",
    "            inputDf[col].fillna(0,inplace=True)\n",
    "\n",
    "        #model and prediction\n",
    "        modelNum = (regions_stats[regions_stats['region']==regionTest])['model'].iloc[0]\n",
    "        model = Utils.BASE_MODELS[modelNum]\n",
    "        model.fit(xdata,ydata)\n",
    "        prediction = teamBlueTest if model.predict(inputDf)==0 else teamRedTest\n",
    "        print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25046f8d",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c586526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
