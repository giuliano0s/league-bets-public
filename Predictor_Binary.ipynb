{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07ebcb47",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed29b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "import json\n",
    "\n",
    "from Utils.constants import *\n",
    "import Utils.utils_file as utils_file\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36bef382",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d199165f",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c267291",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = False\n",
    "\n",
    "target='Score'\n",
    "split_type = 0\n",
    "default_model = 7\n",
    "\n",
    "Utils = utils_file.Utils_Class(target=target\n",
    "                                ,split_type=split_type\n",
    "                                ,default_model=default_model\n",
    "                                ,cache_model=False\n",
    "                                ,cache_scraping=True)\n",
    "\n",
    "Utils.TARGET_DF = Utils.TARGET_DF[(Utils.TARGET_DF[Utils.TARGET]!=2)\n",
    "                                  & (Utils.TARGET_DF['realSemesterYear'].astype(int)<=int(Utils.SEMESTER_YEAR))]\n",
    "\n",
    "regions_to_feed, regions_to_predict = Utils.region_lists(min_entries=30)\n",
    "Utils.define_models('binary')\n",
    "\n",
    "if cache:\n",
    "    regions_feature_cols = Utils.regions_feature_cols\n",
    "    regions_train_data = Utils.regions_train_data\n",
    "\n",
    "#regions_to_predict.remove('MSI')\n",
    "#regions_to_predict.remove('World')\n",
    "regions_to_predict = regions_to_predict[:5]\n",
    "#regions_to_predict = ['MSI','World']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfa4dfa9",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5291e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_stats = pd.DataFrame(columns=['region','model','size'])\n",
    "regions_stats['region'] = regions_to_predict\n",
    "regions_list = regions_stats['region']\n",
    "regions_stats['model'] = Utils.DEFAULT_MODEL\n",
    "\n",
    "regions_train_data = dict(zip(regions_list,regions_list.apply(lambda x: [x])))\n",
    "regions_stats['accuracy_0'] = np.nan\n",
    "regions_stats['accuracy_1'] = np.nan\n",
    "regions_stats['accuracy_2'] = np.nan\n",
    "regions_stats['cut_off_var'] = 1.5\n",
    "\n",
    "regions_feature_cols = dict(zip(regions_list,[0]*len(regions_list)))\n",
    "for key in regions_feature_cols:\n",
    "    regions_feature_cols[key] = PLAYER_SIMPLE_FEATURE_COLS.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a78da8e3",
   "metadata": {},
   "source": [
    "### TRAIN DATA SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c23655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LCS -> nan:\n",
      "\n",
      "0.441 -> OPL added                                           \n",
      "0.409 -> SuperLiga_Tier2 added                                           \n",
      "0.398 -> Hitpoint_Tier2 added                                           \n",
      "0.366 -> EU added                                           \n",
      "\n",
      "\n",
      "accuracy: 0.366\n",
      "LCS train data: ['LCS', 'OPL', 'SuperLiga_Tier2', 'Hitpoint_Tier2', 'EU']\n",
      "len:5\n",
      "test data len: 93\n",
      "\n",
      "=========\n",
      "\n",
      "[2 of 5] region LEC -> nan:\n",
      "\n",
      "0.557 -> TCL added                                           \n",
      "0.511 -> Demacia added                                           \n",
      "0.489 -> NACL added                                           \n",
      "0.458 -> CK added                                           \n",
      "0.443 -> MCR added                                           \n",
      "0.42 -> Baltic added                                           \n",
      "0.412 -> LJL_Tier2 added                                           \n",
      "0.405 -> Mid-Season added                                           \n",
      "\n",
      "\n",
      "accuracy: 0.405\n",
      "LEC train data: ['LEC', 'TCL', 'Demacia', 'NACL', 'CK', 'MCR', 'Baltic', 'LJL_Tier2', 'Mid-Season']\n",
      "len:9\n",
      "test data len: 131\n",
      "\n",
      "=========\n",
      "\n",
      "[3 of 5] region CBLOL_Tier2 -> nan:\n",
      "\n",
      "0.456 -> LVP2 added                                           \n",
      "0.444 -> Elite_Tier2 added                                           \n",
      "0.433 -> LCS_Tier2 added                                           \n",
      "0.422 -> LCK added                                           \n",
      "0.411 -> World added                                           \n",
      "0.4 -> PCS added                                           \n",
      "0.389 -> NLC added                                           \n",
      "\n",
      "\n",
      "accuracy: 0.389\n",
      "CBLOL_Tier2 train data: ['CBLOL_Tier2', 'LVP2', 'Elite_Tier2', 'LCS_Tier2', 'LCK', 'World', 'PCS', 'NLC']\n",
      "len:8\n",
      "test data len: 90\n",
      "\n",
      "=========\n",
      "\n",
      "[4 of 5] region TCL -> nan:\n",
      "\n",
      "0.494 -> Elite_Tier2 added                                           \n",
      "0.418 -> EU added                                           \n",
      "0.392 -> CBLOL_Tier2 added                                           \n",
      "0.38 -> Iberian added                                           \n",
      "\n",
      "\n",
      "accuracy: 0.38\n",
      "TCL train data: ['TCL', 'Elite_Tier2', 'EU', 'CBLOL_Tier2', 'Iberian']\n",
      "len:5\n",
      "test data len: 79\n",
      "\n",
      "=========\n",
      "\n",
      "[5 of 5] region LJL -> nan:\n",
      "\n",
      "0.361 -> Elite_Tier2 added                                           \n",
      "0.331 -> LJL_Tier2 added                                           \n",
      "0.286 -> LPL added                                           \n",
      "0.271 -> LCO added                                           \n",
      "0.263 -> Prime added                                           \n",
      "0.241 -> Demacia added                                           \n",
      "\n",
      "\n",
      "accuracy: 0.241\n",
      "LJL train data: ['LJL', 'Elite_Tier2', 'LJL_Tier2', 'LPL', 'LCO', 'Prime', 'Demacia']\n",
      "len:7\n",
      "test data len: 133\n",
      "\n",
      "0.3562\n"
     ]
    }
   ],
   "source": [
    "regions_train_data = dict(zip(regions_list,regions_list.apply(lambda x: [x])))\n",
    "regions_stats['accuracy_0'] = np.nan\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regions_stats['accuracy_0'][n]\n",
    "    tempTournamentId = region + str(Utils.LAST_SEMESTER_YEAR)\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    region_model_number = regions_stats['model'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    \n",
    "    regionsToTest = [x for x in regions_to_feed]\n",
    "    regionsToTest.remove(region)\n",
    "    random.shuffle(regionsToTest)\n",
    "    for nn,regionToTest in enumerate(regionsToTest):\n",
    "        regions_train_data[region].append(regionToTest)\n",
    "        \n",
    "        metric, pred = Utils.generate_metric(region_model_number, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], tempTournamentId, reps=5)\n",
    "        \n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            \n",
    "            print(f'{regionFinalAcc} -> {regionToTest} added                                           ')\n",
    "        else:\n",
    "            regions_train_data[region].remove(regionToTest)\n",
    "    \n",
    "    regions_stats['accuracy_0'][n] = regionFinalAcc\n",
    "    regions_stats['size'][n] = len(pred)\n",
    "    \n",
    "    print(f'\\n\\naccuracy: {regionFinalAcc}')\n",
    "    print(f'{region} train data: {regions_train_data[region]}\\nlen:{len(regions_train_data[region])}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "\n",
    "mean_acc = np.mean(regions_stats['accuracy_0'])\n",
    "print(mean_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35642234",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a9c57f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LCS -> 0.366:\n",
      "\n",
      "model: 7\n",
      "\n",
      "\n",
      "accuracy: 0.366\n",
      "LCS feature count: 22\n",
      "test data len: 93\n",
      "\n",
      "=========\n",
      "\n",
      "[2 of 5] region LEC -> 0.405:\n",
      "\n",
      "model: 7\n",
      "\n",
      "\n",
      "accuracy: 0.405\n",
      "LEC feature count: 22\n",
      "test data len: 131\n",
      "\n",
      "=========\n",
      "\n",
      "[3 of 5] region CBLOL_Tier2 -> 0.389:\n",
      "\n",
      "model: 7\n",
      "\n",
      "\n",
      "accuracy: 0.389\n",
      "CBLOL_Tier2 feature count: 22\n",
      "test data len: 90\n",
      "\n",
      "=========\n",
      "\n",
      "[4 of 5] region TCL -> 0.38:\n",
      "\n",
      "model: 7\n",
      "\n",
      "\n",
      "accuracy: 0.38\n",
      "TCL feature count: 22\n",
      "test data len: 79\n",
      "\n",
      "=========\n",
      "\n",
      "[5 of 5] region LJL -> 0.241:\n",
      "\n",
      "model: 7\n",
      "DPM removed for 0.233                                                \n",
      "XPD@15 removed for 0.226                                                \n",
      "Penta_Kills removed for 0.211                                                \n",
      "\n",
      "\n",
      "accuracy: 0.211\n",
      "LJL feature count: 19\n",
      "test data len: 133\n",
      "\n",
      "0.3502\n"
     ]
    }
   ],
   "source": [
    "regions_stats['accuracy_1'] = np.nan\n",
    "regions_feature_cols = dict(zip(regions_list,[0]*len(regions_list)))\n",
    "for key in regions_feature_cols:\n",
    "    regions_feature_cols[key] = PLAYER_SIMPLE_FEATURE_COLS.copy()\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regions_stats['accuracy_0'][n]\n",
    "    tempTournamentId = region + str(Utils.LAST_SEMESTER_YEAR)\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    region_model_number = regions_stats['model'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    print(f'model: {region_model_number}')\n",
    "    \n",
    "    initialFeatures = regions_feature_cols[region].copy()\n",
    "    for nn,feature in enumerate(initialFeatures):\n",
    "        regions_feature_cols[region].remove(feature)\n",
    "        \n",
    "        metric, pred = Utils.generate_metric(region_model_number, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], tempTournamentId, reps=5)\n",
    "        \n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            print(f'{feature} removed for {metric}                                                ')\n",
    "        else:\n",
    "            regions_feature_cols[region].append(feature)\n",
    "    \n",
    "    regions_stats['accuracy_1'][n] = regionFinalAcc\n",
    "    print(f'\\n\\naccuracy: {regionFinalAcc}')\n",
    "    print(f'{region} feature count: {len(regions_feature_cols[region])}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "    \n",
    "mean_acc = np.mean(regions_stats['accuracy_1'])\n",
    "print(mean_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c01c99",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd7a21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LCS -> 0.366:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.445\n",
      "model 1 -> 0.548\n",
      "model 2 -> 0.426\n",
      "model 3 -> 0.458\n",
      "model 4 -> 0.409\n",
      "model 5 -> 0.54\n",
      "model 6 -> 0.452\n",
      "model 7 -> 0.366\n",
      "\n",
      "accuracy: 0.366\n",
      "best model: 7\n",
      "\n",
      "=========\n",
      "\n",
      "[2 of 5] region LEC -> 0.405:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.534\n",
      "model 1 -> 0.427\n",
      "model 2 -> 0.481\n",
      "model 3 -> 0.507\n",
      "model 4 -> 0.435\n",
      "model 5 -> 0.485\n",
      "model 6 -> 0.466\n",
      "model 7 -> 0.405\n",
      "\n",
      "accuracy: 0.405\n",
      "best model: 7\n",
      "\n",
      "=========\n",
      "\n",
      "[3 of 5] region CBLOL_Tier2 -> 0.389:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.484\n",
      "model 1 -> 0.6\n",
      "model 2 -> 0.467\n",
      "model 3 -> 0.489\n",
      "model 4 -> 0.482\n",
      "model 5 -> 0.471\n",
      "model 6 -> 0.467\n",
      "model 7 -> 0.389\n",
      "\n",
      "accuracy: 0.389\n",
      "best model: 7\n",
      "\n",
      "=========\n",
      "\n",
      "[4 of 5] region TCL -> 0.38:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.552\n",
      "model 1 -> 0.506\n",
      "model 2 -> 0.519\n",
      "model 3 -> 0.514\n",
      "model 4 -> 0.519\n",
      "model 5 -> 0.552\n",
      "model 6 -> 0.456\n",
      "model 7 -> 0.38\n",
      "\n",
      "accuracy: 0.38\n",
      "best model: 7\n",
      "\n",
      "=========\n",
      "\n",
      "[5 of 5] region LJL -> 0.241:\n",
      "\n",
      "current model: 7\n",
      "\n",
      "model 0 -> 0.408\n",
      "model 1 -> 0.459\n",
      "model 2 -> 0.346\n",
      "model 3 -> 0.367\n",
      "model 4 -> 0.337\n",
      "model 5 -> 0.589\n",
      "model 6 -> 0.361\n",
      "model 7 -> 0.211\n",
      "\n",
      "accuracy: 0.211\n",
      "best model: 7\n",
      "\n",
      "0.3502\n"
     ]
    }
   ],
   "source": [
    "regions_stats['accuracy_2'] = np.nan\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    currAcc = regions_stats['accuracy_0'][n]\n",
    "    currModel = regions_stats['model'][n]\n",
    "    tempTournamentId = region + str(Utils.LAST_SEMESTER_YEAR)\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {currAcc}:\\n')\n",
    "    print(f'current model: {currModel}\\n')\n",
    "    \n",
    "    bestModelAbs = (regions_stats[regions_stats['region']==region])['accuracy_2'].iloc[0]\n",
    "    for model in range(len(Utils.BASE_MODELS)):\n",
    "        metric, pred = Utils.generate_metric(model, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], tempTournamentId, reps=5)\n",
    "        if metric < bestModelAbs or np.isnan(bestModelAbs):\n",
    "            bestModelAbs = metric\n",
    "            bestModel = model\n",
    "        print(f'model {model} -> {metric}')\n",
    "\n",
    "    regions_stats['model'][n] = bestModel\n",
    "    regions_stats['accuracy_2'][n] = bestModelAbs\n",
    "    \n",
    "    print(f'\\naccuracy: {bestModelAbs}')\n",
    "    print(f'best model: {bestModel}\\n')\n",
    "    \n",
    "mean_acc = np.mean(regions_stats['accuracy_2'])\n",
    "print(mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0f194c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_cache = dict()\n",
    "regions_cache['features'] = regions_feature_cols\n",
    "regions_cache['train_data'] = regions_train_data\n",
    "\n",
    "with open(f'Data/raw_data/regions_cache.json', 'w') as fp:\n",
    "    json.dump(regions_cache, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87477a1d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3082\n",
      "0.2934\n",
      "0.2914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>accuracy_0</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>cut_off_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LPL</td>\n",
       "      <td>6</td>\n",
       "      <td>329</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.307</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LCK</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.298</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCS</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.295</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCS</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.261</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultraliga</td>\n",
       "      <td>7</td>\n",
       "      <td>108</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.296</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region  model size  accuracy_0  accuracy_1  accuracy_2  cut_off_var\n",
       "0        LPL      6  329       0.350       0.307       0.307          1.5\n",
       "1        LCK      7  248       0.298       0.298       0.298          1.5\n",
       "2        PCS      1  105       0.314       0.305       0.295          1.5\n",
       "3        VCS      7   92       0.283       0.261       0.261          1.5\n",
       "4  Ultraliga      7  108       0.296       0.296       0.296          1.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(regions_stats['accuracy_0']))\n",
    "print(np.mean(regions_stats['accuracy_1']))\n",
    "print(np.mean(regions_stats['accuracy_2']))\n",
    "regions_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab7301bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_names(name):\n",
    "    tempDf = Utils.team_data_table[(Utils.team_data_table['Name']==name)\n",
    "                           & (Utils.team_data_table['Year'].astype(int)==Utils.YEAR)\n",
    "                           & (Utils.team_data_table['Semester'].astype(int)==Utils.SEMESTER)]\n",
    "    \n",
    "    namesList = tempDf[['TOP','JNG','MID','ADC','SUP']].iloc[0]\n",
    "    \n",
    "    return namesList\n",
    "\n",
    "def get_feature_team_mean(namesList,feature):\n",
    "    values=[]\n",
    "    noDataList=[]\n",
    "    for name in namesList:\n",
    "        filteredTempDf = Utils.player_data_table[(Utils.player_data_table['Player']==name)\n",
    "                                             & (Utils.player_data_table['Year']==Utils.YEAR)\n",
    "                                             & (Utils.player_data_table['Semester']==Utils.SEMESTER)]\n",
    "        \n",
    "        valueToAppend = filteredTempDf[feature.replace('Team_Red_','').replace('Team_Blue_','')]\n",
    "        if len(valueToAppend)>0:\n",
    "            values.append(valueToAppend.iloc[0])\n",
    "        else: \n",
    "            noDataList.append(name)\n",
    "    \n",
    "    return np.mean(values),noDataList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a04ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'CNB e-Sports Club',\n",
       " 1: 'FURIA Esports',\n",
       " 2: 'FURIA Uppercut',\n",
       " 3: 'Flamengo Los Grandes',\n",
       " 4: 'Flamengo eSports',\n",
       " 5: 'Fluxo',\n",
       " 6: 'INTZ e-Sports',\n",
       " 7: 'INTZ eSports',\n",
       " 8: 'KaBuM! e-Sports',\n",
       " 9: 'LOUD',\n",
       " 10: 'Liberty',\n",
       " 11: 'Los Grandes',\n",
       " 12: 'Netshoes Miners',\n",
       " 13: 'Prodigy Esports',\n",
       " 14: 'RED Canids',\n",
       " 15: 'Redemption POA',\n",
       " 16: 'Rensga eSports',\n",
       " 17: 'Santos e-Sports',\n",
       " 18: 'Team oNe eSports',\n",
       " 19: 'Uppercut eSports',\n",
       " 20: 'Vivo Keyd',\n",
       " 21: 'Vivo Keyd Stars',\n",
       " 22: 'Vorax Liberty',\n",
       " 23: 'paiN Gaming'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regionTest = 'CBLOL'\n",
    "dfTemp = Utils.TARGET_DF[Utils.TARGET_DF['regionAbrev']==regionTest]\n",
    "teamsSet = sorted(set(list(dfTemp['Blue'].unique())+list(dfTemp['Red'].unique())))\n",
    "teamsDict = dict(zip(range(len(teamsSet)),teamsSet))\n",
    "teamsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b14490bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teamBlueNames = ['fNb', 'Goot', 'Envy', 'Netuno', 'RedBert']\n",
      "teamRedNames = ['Kiari', 'Disamis', 'Krastyel', 'Cavalo', 'Matsukaze']\n"
     ]
    }
   ],
   "source": [
    "team0 = 1\n",
    "team1 = 10\n",
    "\n",
    "playerNames = Utils.team_data_table[(Utils.team_data_table['Name']==teamsDict[team0])\n",
    "                            & (Utils.team_data_table['Year'].astype(int)==Utils.YEAR)\n",
    "                            & (Utils.team_data_table['Semester'].astype(int)==Utils.SEMESTER)][['TOP','JNG','MID','ADC','SUP']]\n",
    "\n",
    "try: print(f'teamBlueNames = {list(playerNames.values[0])}')\n",
    "except: print('no team found')\n",
    "\n",
    "playerNames = Utils.team_data_table[(Utils.team_data_table['Name']==teamsDict[team1])\n",
    "                            & (Utils.team_data_table['Year'].astype(int)==Utils.YEAR)\n",
    "                            & (Utils.team_data_table['Semester'].astype(int)==Utils.SEMESTER)][['TOP','JNG','MID','ADC','SUP']]\n",
    "\n",
    "try:print(f'teamRedNames = {list(playerNames.values[0])}')\n",
    "except: print('no team found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59059b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "=================\n",
      "no data names on: []\n",
      "FURIA Esports\n",
      "no data names on: []\n",
      "FURIA Esports\n"
     ]
    }
   ],
   "source": [
    "manualNameInsert = 1\n",
    "\n",
    "for i in range(5):\n",
    "    print('=================')\n",
    "    for swap in [0,1]:\n",
    "        #teams\n",
    "        teamBlueNames = ['fNb', 'Goot', 'Envy', 'Trigo', 'RedBert']\n",
    "        teamRedNames = ['Kiari', 'accez', 'Piloto', 'Juliera', 'Cavalo']\n",
    "        teamBlueTest = teamsDict[team0]\n",
    "        teamRedTest = teamsDict[team1]\n",
    "        if swap==1:\n",
    "                teamTemp = teamBlueTest\n",
    "                teamBlueTest = teamRedTest\n",
    "                teamRedTest = teamTemp\n",
    "\n",
    "                teamNamesTemp = teamBlueNames\n",
    "                teamBlueNames = teamRedNames\n",
    "                teamRedNames = teamNamesTemp\n",
    "\n",
    "        #generate train data\n",
    "        finalDfInput = Utils.TARGET_DF[Utils.TARGET_DF['regionAbrev'].isin(regions_train_data[regionTest])].copy()\n",
    "        finalDfInput = finalDfInput.sort_values(by='Date',ascending=True)\n",
    "        for col in finalDfInput.columns:\n",
    "                    finalDfInput[col].fillna(0,inplace=True)\n",
    "\n",
    "        featureColsFiltered = [x for x in list(finalDfInput.columns) \n",
    "                               if x.replace('Team_Blue_','').replace('Team_Red_','') in regions_feature_cols[regionTest]]\n",
    "        \n",
    "        xdata= finalDfInput[featureColsFiltered]\n",
    "        ydata = finalDfInput[Utils.TARGET]\n",
    "\n",
    "        #generate features to predict\n",
    "        if manualNameInsert==0:\n",
    "            teamBlueNames = get_team_names(teamBlueTest)\n",
    "            teamRedNames = get_team_names(teamRedTest)\n",
    "\n",
    "        inputFeatures = Utils.TARGET_DF.drop([Utils.TARGET+'Data']+OFF_COLS,axis=1,errors='ignore').columns\n",
    "        featuresDict = {}\n",
    "        for feature in featureColsFiltered:\n",
    "            side = feature.split('_')[1]\n",
    "            if side == 'Blue':\n",
    "                featuresDict[feature],noDataNames = get_feature_team_mean(teamBlueNames,feature)\n",
    "                \n",
    "            elif side == 'Red':\n",
    "                featuresDict[feature],noDataNames = get_feature_team_mean(teamRedNames,feature)\n",
    "        print(f'no data names on: {noDataNames}')\n",
    "\n",
    "        inputDf = pd.DataFrame(featuresDict.values(),index=featuresDict.keys()).transpose()\n",
    "        for col in inputDf.columns:\n",
    "            inputDf[col].fillna(0,inplace=True)\n",
    "\n",
    "        #model and prediction\n",
    "        modelNum = (regions_stats[regions_stats['region']==regionTest])['model'].iloc[0]\n",
    "        model = Utils.BASE_MODELS[modelNum]\n",
    "        model.fit(xdata,ydata)\n",
    "        prediction = teamBlueTest if model.predict(inputDf)==0 else teamRedTest\n",
    "        print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25046f8d",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c586526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
