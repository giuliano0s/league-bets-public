{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eca7822",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed29b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_2194033878269879953() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_2194033878269879953()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, RepeatedKFold, cross_val_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import AffinityPropagation as AP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import re\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath\n",
    "                (os.path.join\n",
    "                 (os.path.dirname(\"constants.py\"), '..')))\n",
    "from constants import *\n",
    "from scripts import *\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36bef382",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f53be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_logistic(dfToSplitFunc, tournamentId, currentTarget, cut_off_var, splitType, verbose=True):\n",
    "    \n",
    "    for col in dfToSplitFunc.columns:\n",
    "            dfToSplitFunc[col] = dfToSplitFunc[col].fillna(0)\n",
    "    \n",
    "    if splitType==0:\n",
    "        testData = dfToSplitFunc[dfToSplitFunc['tournament_id']==tournamentId].copy()\n",
    "        xtest= testData.drop(['Date',currentTarget],axis=1).copy()\n",
    "        xtest= xtest.drop(offCols,axis=1,errors='ignore')\n",
    "        ytest = testData[currentTarget]\n",
    "\n",
    "        trainData = dfToSplitFunc[dfToSplitFunc['tournament_id']!=tournamentId].copy()\n",
    "        xtrain = trainData.drop(['Date',currentTarget],axis=1).copy()\n",
    "        xtrain = xtrain.drop(offCols,axis=1,errors='ignore')\n",
    "        ytrain = trainData[currentTarget]\n",
    "        \n",
    "    elif splitType==1:\n",
    "        #print(dfToSplitFunc.columns)\n",
    "        xCols = dfToSplitFunc.drop(['Date', currentTarget]+offCols,axis=1,errors='ignore')\n",
    "        #print(xCols.columns)\n",
    "        yCols = dfToSplitFunc[currentTarget]\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(xCols, yCols, test_size=0.20, shuffle=False)\n",
    "    \n",
    "    if list(ytrain).count(0)/len(ytrain)==1:\n",
    "        print(len(ytrain))\n",
    "        print(dropTypeF)\n",
    "        print(dfToSplitFunc[currentTarget])\n",
    "        print('==========================================================')\n",
    "    \n",
    "    ytrain_mean, ytrain_std = np.mean(ytrain), np.std(ytrain)\n",
    "    cut_off = ytrain_std * cut_off_var\n",
    "    lower, upper = ytrain_mean - cut_off, ytrain_mean + cut_off\n",
    "    \n",
    "    outlierMask = ytrain.apply(lambda x: False if x < lower or x > upper else True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'train len: {len(xtrain)}')\n",
    "    lentemp = len(xtrain)\n",
    "    #xtrain, ytrain = xtrain[outlierMask], ytrain[outlierMask]\n",
    "    if verbose:\n",
    "        print(f'train len no outliers: {len(xtrain)}')\n",
    "        print(f'percent of len removed: {round(abs(len(xtrain)/lentemp*100-100),2)}%')\n",
    "        print(f'test len: {len(xtest)}\\n')\n",
    "    \n",
    "    return xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16968446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6134052449046805136() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6134052449046805136()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matchListToDfs(df):\n",
    "    matchListDateFilter = (df[df['Date'] >= pd.to_datetime('2019-7-01',format='%Y-%m-%d')]\n",
    "                                        .reset_index(drop=True).copy())\n",
    "    matchListDateFilter['realSemesterYear'] = (matchListDateFilter['realYear'].astype(str)\n",
    "                                               +matchListDateFilter['realSemester'].astype(str))\n",
    "    matchListDateFilter['tournament_id'] = (matchListDateFilter['TournamentRegion'].astype(str)\n",
    "                                               +matchListDateFilter['realSemesterYear'].astype(str))\n",
    "    \n",
    "    playerMatchList = matchListDateFilter.copy()\n",
    "    teamMatchList = matchListDateFilter.copy()\n",
    "\n",
    "    for color in ['Blue','Red']:\n",
    "        for feature in meanFeatures:\n",
    "                teamMatchList[f'Team_{color}_{feature}'] = (matchListDateFilter[[f\"{position}_{color}_{feature}\" for position in positions]]\n",
    "                                                        .mean(skipna=True,axis=1).copy())\n",
    "                teamMatchList.drop([f\"{position}_{color}_{feature}\" for position in positions],axis=1,inplace=True)\n",
    "\n",
    "        for feature in sumFeatures:\n",
    "                teamMatchList[f'Team_{color}_{feature}'] = (matchListDateFilter[[f\"{position}_{color}_{feature}\" for position in positions]]\n",
    "                                                        .sum(skipna=True,axis=1).copy())\n",
    "                teamMatchList.drop([f\"{position}_{color}_{feature}\" for position in positions],axis=1,inplace=True)\n",
    "\n",
    "        teamMatchList.drop([f\"{position}_{color}\" for position in positions],axis=1,inplace=True)\n",
    "        \n",
    "    return playerMatchList, teamMatchList\n",
    "\n",
    "def regionLists(df, currentYear):\n",
    "    regions = df['TournamentRegion'].unique()\n",
    "    regionsToFeed = [x for x in df['TournamentRegion'].unique()]\n",
    "    regionsFilterTemp = ([x for x in regions if currentYear in (df[df['TournamentRegion']==x])['realYear'].unique()\n",
    "                                            and currentYear-1 in (df[df['TournamentRegion']==x])['realYear'].unique()])\n",
    "    regionsToPredict = []\n",
    "    for region in regionsFilterTemp:\n",
    "        regionsFilterSize = df[(df['realYear']==currentYear) & (df['TournamentRegion']==region)]\n",
    "        regionsFilterSizeTrain = df[(df['realYear']!=currentYear) & (df['TournamentRegion']==region)]\n",
    "        if len(regionsFilterSize)>=30:\n",
    "            regionsToPredict.append(region)\n",
    "    \n",
    "    return regions, regionsToFeed, regionsToPredict\n",
    "\n",
    "def generateRegionDf(df, regionDataListF, regionsFeatureColsF, cut_off_var, tempTournamentIdF, currentTarget, splitType):\n",
    "    \n",
    "    dfTemp = df[df['TournamentRegion'].isin(regionDataListF)].copy()\n",
    "    tempCols = [x for x in list(dfTemp.columns) if x.split('_')[-1] in regionsFeatureColsF]\n",
    "    dfTemp = dfTemp[tempCols+infoCols]\n",
    "    dfTemp = dfTemp.sort_values(by='Date',ascending=True).copy()\n",
    "    \n",
    "    xtrain,ytrain,xtest,ytest = train_test_split_logistic(dfTemp, tempTournamentIdF, currentTarget, cut_off_var, splitType, verbose=False)\n",
    "    \n",
    "    return dfTemp, xtrain, ytrain, xtest, ytest\n",
    "\n",
    "def generateMetric(model_number, regionDataListF, regionsFeatureColsF, cut_off_var, tempTournamentIdF, currentTarget, dfToSplit, splitType):\n",
    "    \n",
    "    dfTemp, xtrain, ytrain, xtest, ytest = generateRegionDf(dfToSplit, regionDataListF, regionsFeatureColsF\n",
    "                                                            , cut_off_var, tempTournamentIdF, currentTarget, splitType)\n",
    "    \n",
    "    region_model = base_models[model_number]\n",
    "    region_model.fit(xtrain, ytrain)\n",
    "    \n",
    "    errors3=0\n",
    "    rep=3\n",
    "    for i in range(rep):\n",
    "        region_model.fit(xtrain, ytrain)\n",
    "        pred = region_model.predict_proba(xtest)\n",
    "        pred = pred[:,1]\n",
    "        \n",
    "        errors3 = skm.mean_absolute_error(ytest, pred)+errors3\n",
    "    errors2=errors3/rep\n",
    "\n",
    "    errors3=0\n",
    "    for i in range(rep):\n",
    "        region_model.fit(xtrain, ytrain)\n",
    "        pred = region_model.predict_proba(xtest)\n",
    "        pred = pred[:,1]\n",
    "    \n",
    "        errors3 = skm.mean_absolute_error(ytest, pred)+errors3\n",
    "    errors4=errors3/rep\n",
    "    \n",
    "    metric=round((errors2+errors4)/2,3)\n",
    "    \n",
    "    return metric, pred\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d199165f",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4def85",
   "metadata": {},
   "outputs": [],
   "source": [
    "teamDataTable = pd.read_pickle(\"Data/raw_data/teamDataTable.pkl\")\n",
    "playerDataTable = pd.read_pickle(\"Data/raw_data/playerDataTable.pkl\")\n",
    "\n",
    "matchList = pd.read_pickle(\"Data/raw_data/matchList.pkl\")\n",
    "matchListFill = pd.read_pickle(\"Data/raw_data/matchListFill.pkl\")\n",
    "\n",
    "teamMatchList = pd.read_pickle(\"Data/raw_data/teamMatchList.pkl\")\n",
    "playerMatchList = pd.read_pickle(\"Data/raw_data/playerMatchList.pkl\")\n",
    "\n",
    "regionsStats = pd.read_pickle(\"./Data/raw_data/regionsStats.pkl\")\n",
    "\n",
    "with open(f'./Data/raw_data/regionsFeatureCols.json', 'r') as fp:\n",
    "    regionsFeatureCols = json.load(fp)\n",
    "with open(f'./Data/raw_data/regionsTrainData.json', 'r') as fp:\n",
    "    regionsTrainData = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c267291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main df size: 26314\n"
     ]
    }
   ],
   "source": [
    "content=1\n",
    "playerMatchList, teamMatchList = matchListToDfs(matchListFill)\n",
    "#             0              1\n",
    "dfsContent = [playerMatchList, teamMatchList]\n",
    "dfToSplit = dfsContent[content].copy()\n",
    "\n",
    "print(f'main df size: {len(dfToSplit)}')\n",
    "\n",
    "base_models = [\n",
    "              LogisticRegression(solver='newton-cg') #0\n",
    "              ]\n",
    "\n",
    "currentTarget = 'Score'\n",
    "currentYear = 2022\n",
    "currentSemester = 1\n",
    "currentSemesterYear = str(currentYear)+str(currentSemester)\n",
    "defaultModel = 0\n",
    "infoCols = ['Date','tournament_id',currentTarget,'TournamentRegion']\n",
    "splitType = 0\n",
    "\n",
    "if currentTarget == 'Score':\n",
    "    dfToSplit.drop('totalKills',axis=1,inplace=True)\n",
    "elif currentTarget == 'totalKills':\n",
    "    dfToSplit.drop('Score',axis=1,inplace=True)\n",
    "    \n",
    "featureCols = [x for x in dfToSplit.columns if x not in offCols+infoCols]\n",
    "featureCols = list(set([x.replace('Team_Blue_','').replace('Team_Red_','') for x in featureCols]))\n",
    "\n",
    "regions, regionsToFeed, regionsToPredict = regionLists(dfToSplit, currentYear)\n",
    "\n",
    "dfToSplit = dfToSplit[dfToSplit['realSemesterYear'].astype(int)<=int(currentSemesterYear)]\n",
    "\n",
    "regionsToPredict = regionsToPredict[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfa4dfa9",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5291e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regionsStats = pd.DataFrame(columns=['region','model','size'])\n",
    "regionsStats['region'] = regionsToPredict\n",
    "regionsList = regionsStats['region']\n",
    "regionsStats['model'] = defaultModel\n",
    "\n",
    "regionsTrainData = dict(zip(regionsList,regionsList.apply(lambda x: [x])))\n",
    "regionsStats['accuracy_0'] = np.nan\n",
    "regionsStats['accuracy_1'] = np.nan\n",
    "regionsStats['accuracy_2'] = np.nan\n",
    "regionsStats['cut_off_var'] = 1.5\n",
    "\n",
    "regionsFeatureCols = dict(zip(regionsList,[0]*len(regionsList)))\n",
    "for key in regionsFeatureCols:\n",
    "    regionsFeatureCols[key] = featureCols.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a78da8e3",
   "metadata": {},
   "source": [
    "### TRAIN DATA SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c23655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LPL -> nan:\n",
      "\n",
      "0.439 -> MSI added                                           \n",
      "0.438 -> Demacia added                                           \n",
      "0.436 -> LCS_Tier2 added                                           \n",
      "0.434 -> REL added                                           \n",
      "0.433 -> Dutch added                                           \n",
      "0.429 -> NA_Tier2 added                                           \n",
      "0.428 -> EBL added                                           \n",
      "0.424 -> PCS added                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regionsTrainData = dict(zip(regionsList,regionsList.apply(lambda x: [x])))\n",
    "regionsStats['accuracy_0'] = np.nan\n",
    "\n",
    "for n,region in enumerate(regionsToPredict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regionsStats['accuracy_0'][n]\n",
    "    tempTournamentId = region+currentSemesterYear\n",
    "    cut_off_var = regionsStats['cut_off_var'][n]\n",
    "    region_model_number = regionsStats['model'][n]\n",
    "    print(f'[{n+1} of {len(regionsToPredict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    \n",
    "    regionsToTest = [x for x in regionsToFeed]\n",
    "    regionsToTest.remove(region)\n",
    "    random.shuffle(regionsToTest)\n",
    "    for nn,regionToTest in enumerate(regionsToTest):\n",
    "        regionsTrainData[region].append(regionToTest)\n",
    "        \n",
    "        metric, pred = generateMetric(region_model_number, regionsTrainData[region], regionsFeatureCols[region]\n",
    "                                      , cut_off_var, tempTournamentId, currentTarget, dfToSplit, splitType)\n",
    "        \n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            \n",
    "            print(f'{regionFinalAcc} -> {regionToTest} added                                           ')\n",
    "        else:\n",
    "            regionsTrainData[region].remove(regionToTest)\n",
    "            \n",
    "        #print(f'[{nn+1} of {len(regionsToTest)}] testing: {regionToTest}                        ',end='\\r')\n",
    "    \n",
    "    regionsStats['accuracy_0'][n] = regionFinalAcc\n",
    "    regionsStats['size'][n] = len(pred)\n",
    "    \n",
    "    print(f'\\n\\naccuracy: {regionFinalAcc}')\n",
    "    print(f'{region} train data: {regionsTrainData[region]}\\nlen:{len(regionsTrainData[region])}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "    \n",
    "printFinalResults(regionsStats, 'accuracy_0')\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325ceaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>accuracy_0</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>cut_off_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LPL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LCK</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultraliga</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region  model size  accuracy_0  accuracy_1  accuracy_2  cut_off_var\n",
       "0        LPL      0  NaN         NaN         NaN         NaN          1.5\n",
       "1        LCK      0  NaN         NaN         NaN         NaN          1.5\n",
       "2        PCS      0  NaN         NaN         NaN         NaN          1.5\n",
       "3        VCS      0  NaN         NaN         NaN         NaN          1.5\n",
       "4  Ultraliga      0  NaN         NaN         NaN         NaN          1.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(regionsStats['accuracy_0']))\n",
    "print(np.mean(regionsStats['accuracy_1']))\n",
    "print(np.mean(regionsStats['accuracy_2']))\n",
    "regionsStats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35642234",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44a9c57f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LPL -> nan:\n",
      "\n",
      "model: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:20\u001b[0m\n",
      "Cell \u001b[1;32mIn[7], line 58\u001b[0m, in \u001b[0;36mgenerateMetric\u001b[1;34m(model_number, regionDataListF, regionsFeatureColsF, cut_off_var, tempTournamentIdF, currentTarget, dfToSplit, splitType)\u001b[0m\n\u001b[0;32m     54\u001b[0m dfTemp, xtrain, ytrain, xtest, ytest \u001b[38;5;241m=\u001b[39m generateRegionDf(dfToSplit, regionDataListF, regionsFeatureColsF\n\u001b[0;32m     55\u001b[0m                                                         , cut_off_var, tempTournamentIdF, currentTarget, splitType)\n\u001b[0;32m     57\u001b[0m region_model \u001b[38;5;241m=\u001b[39m base_models[model_number]\n\u001b[1;32m---> 58\u001b[0m \u001b[43mregion_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m errors3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     61\u001b[0m rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:468\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    466\u001b[0m     l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    467\u001b[0m     args \u001b[38;5;241m=\u001b[39m (X, target, sample_weight, l2_reg_strength, n_threads)\n\u001b[1;32m--> 468\u001b[0m     w0, n_iter_i \u001b[38;5;241m=\u001b[39m \u001b[43m_newton_cg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewton-cholesky\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;66;03m# The division by sw_sum is a consequence of the rescaling of\u001b[39;00m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;66;03m# sample_weight, see comment above.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C \u001b[38;5;241m/\u001b[39m sw_sum\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:199\u001b[0m, in \u001b[0;36m_newton_cg\u001b[1;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line_search:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m         alphak, fc, gc, old_fval, old_old_fval, gfkp1 \u001b[38;5;241m=\u001b[39m \u001b[43m_line_search_wolfe12\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxsupi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_old_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m _LineSearchError:\n\u001b[0;32m    203\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLine Search failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:39\u001b[0m, in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_line_search_wolfe12\u001b[39m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Same as line_search_wolfe1, but fall back to line_search_wolfe2 if\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    suitable step length is not found, and raise an exception if a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     ret \u001b[38;5;241m=\u001b[39m line_search_wolfe1(f, fprime, xk, pk, gfk, old_fval, old_old_fval, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;66;03m# line search failed: try different one.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         ret \u001b[38;5;241m=\u001b[39m line_search_wolfe2(\n\u001b[0;32m     44\u001b[0m             f, fprime, xk, pk, gfk, old_fval, old_old_fval, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     45\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:84\u001b[0m, in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(gval[\u001b[38;5;241m0\u001b[39m], pk)\n\u001b[0;32m     82\u001b[0m derphi0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(gfk, pk)\n\u001b[1;32m---> 84\u001b[0m stp, fval, old_fval \u001b[38;5;241m=\u001b[39m \u001b[43mscalar_search_wolfe1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_old_fval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderphi0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stp, fc[\u001b[38;5;241m0\u001b[39m], gc[\u001b[38;5;241m0\u001b[39m], fval, old_fval, gval[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:161\u001b[0m, in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    159\u001b[0m     alpha1 \u001b[38;5;241m=\u001b[39m stp\n\u001b[0;32m    160\u001b[0m     phi1 \u001b[38;5;241m=\u001b[39m phi(stp)\n\u001b[1;32m--> 161\u001b[0m     derphi1 \u001b[38;5;241m=\u001b[39m \u001b[43mderphi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:78\u001b[0m, in \u001b[0;36mline_search_wolfe1.<locals>.derphi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mderphi\u001b[39m(s):\n\u001b[1;32m---> 78\u001b[0m     gval[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfprime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     gc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(gval[\u001b[38;5;241m0\u001b[39m], pk)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:346\u001b[0m, in \u001b[0;36mLinearModelLoss.gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    343\u001b[0m n_dof \u001b[38;5;241m=\u001b[39m n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_prediction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     weights, intercept, raw_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_intercept_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:165\u001b[0m, in \u001b[0;36mLinearModelLoss.weight_intercept_raw\u001b[1;34m(self, coef, X)\u001b[0m\n\u001b[0;32m    162\u001b[0m     raw_prediction \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m weights \u001b[38;5;241m+\u001b[39m intercept\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# weights has shape (n_classes, n_dof)\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     raw_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m \u001b[38;5;241m+\u001b[39m intercept  \u001b[38;5;66;03m# ndarray, likely C-contiguous\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights, intercept, raw_prediction\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regionsStats['accuracy_1'] = np.nan\n",
    "regionsFeatureCols = dict(zip(regionsList,[0]*len(regionsList)))\n",
    "\n",
    "for key in regionsFeatureCols:\n",
    "    regionsFeatureCols[key] = featureCols.copy()\n",
    "\n",
    "for n,region in enumerate(regionsToPredict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regionsStats['accuracy_0'][n]\n",
    "    tempTournamentId = region+currentSemesterYear\n",
    "    cut_off_var = regionsStats['cut_off_var'][n]\n",
    "    region_model_number = regionsStats['model'][n]\n",
    "    print(f'[{n+1} of {len(regionsToPredict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    print(f'model: {region_model_number}')\n",
    "    \n",
    "    initialFeatures = regionsFeatureCols[region].copy()\n",
    "    for nn,feature in enumerate(initialFeatures):\n",
    "        regionsFeatureCols[region].remove(feature)\n",
    "    \n",
    "        metric, pred = generateMetric(region_model_number, regionsTrainData[region], regionsFeatureCols[region]\n",
    "                                      , cut_off_var, tempTournamentId, currentTarget, dfToSplit, splitType)\n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            print(f'{feature} removed for {metric}                                                ')\n",
    "        else:\n",
    "            regionsFeatureCols[region].append(feature)\n",
    "            \n",
    "        print(f'[{nn+1} of {len(initialFeatures)}] testing: {feature}                        ',end='\\r')\n",
    "    \n",
    "    regionsStats['accuracy_1'][n] = regionFinalAcc\n",
    "    print(f'\\n\\naccuracy: {regionFinalAcc}')\n",
    "    print(f'{region} feature count: {len(regionsFeatureCols[region])}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "    \n",
    "printFinalResults(regionsStats, 'accuracy_1')\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c01c99",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd7a21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 21] region LPL -> 0.388:\n",
      "\n",
      "current model: 4\n",
      "\n",
      "model 0 -> 0.328\n",
      "model 1 -> 0.34\n",
      "model 2 -> 0.483\n",
      "model 3 -> 0.299\n",
      "model 4 -> 0.403\n",
      "model 5 -> 0.395\n",
      "model 6 -> 0.488\n",
      "model 7 -> 0.322\n",
      "\n",
      "accuracy: 0.299\n",
      "best model: 3\n",
      "\n",
      "=========\n",
      "\n",
      "[2 of 21] region LCK -> 0.321:\n",
      "\n",
      "current model: 4\n",
      "\n",
      "model 0 -> 0.333\n",
      "model 1 -> 0.282\n",
      "model 2 -> 0.435\n",
      "model 3 -> 0.319\n",
      "model 4 -> 0.354\n",
      "model 5 -> 0.359\n",
      "model 6 -> 0.391\n",
      "model 7 -> 0.319\n",
      "\n",
      "accuracy: 0.282\n",
      "best model: 1\n",
      "\n",
      "=========\n",
      "\n",
      "[3 of 21] region PCS -> 0.337:\n",
      "\n",
      "current model: 4\n",
      "\n",
      "model 0 -> 0.354\n",
      "model 1 -> 0.324\n",
      "model 2 -> 0.343\n",
      "model 3 -> 0.298\n",
      "model 4 -> 0.386\n",
      "model 5 -> 0.448\n",
      "model 6 -> 0.465\n",
      "model 7 -> 0.305\n",
      "\n",
      "accuracy: 0.298\n",
      "best model: 3\n",
      "\n",
      "=========\n",
      "\n",
      "[4 of 21] region VCS -> 0.404:\n",
      "\n",
      "current model: 4\n",
      "\n",
      "model 0 -> 0.458\n",
      "model 1 -> 0.348\n",
      "model 2 -> 0.5\n",
      "model 3 -> 0.402\n",
      "model 4 -> 0.482\n",
      "model 5 -> 0.536\n",
      "model 6 -> 0.375\n",
      "model 7 -> 0.424\n",
      "\n",
      "accuracy: 0.348\n",
      "best model: 1\n",
      "\n",
      "=========\n",
      "\n",
      "[5 of 21] region Ultraliga -> 0.366:\n",
      "\n",
      "current model: 4\n",
      "\n",
      "model 0 -> 0.364\n",
      "model 1 -> 0.528\n",
      "model 2 -> 0.528\n",
      "model 3 -> 0.37\n",
      "model 4 -> 0.417\n",
      "model 5 -> 0.435\n",
      "model 6 -> 0.404\n",
      "model 7 -> 0.38\n",
      "\n",
      "accuracy: 0.364\n",
      "best model: 0\n",
      "\n",
      "=========\n",
      "\n",
      "[6 of 21] region LLA -> 0.354:\n",
      "\n",
      "current model: 4\n",
      "\n",
      "model 0 -> 0.354\n",
      "model 1 -> 0.354\n",
      "model 2 -> 0.354\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:14\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m, in \u001b[0;36mgenerateMetric\u001b[1;34m(model_number, regionDataListF, regionsFeatureColsF, cut_off_var, tempTournamentIdF, currentTarget, dfToSplit)\u001b[0m\n\u001b[0;32m     53\u001b[0m dfTemp, xtrain, ytrain, xtest, ytest \u001b[38;5;241m=\u001b[39m generateRegionDf(dfToSplit, regionDataListF, regionsFeatureColsF\n\u001b[0;32m     54\u001b[0m                                                         , cut_off_var, tempTournamentIdF, currentTarget)\n\u001b[0;32m     56\u001b[0m region_model \u001b[38;5;241m=\u001b[39m base_models[model_number]\n\u001b[1;32m---> 57\u001b[0m \u001b[43mregion_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m errors3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     60\u001b[0m rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py:274\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    271\u001b[0m check_classification_targets(y)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m# and LogisticRegression but LogisticRegression sets a structured\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# `n_iter_` attribute with information about the underlying OvR fits\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# while LinearSVC/R only reports the maximum value.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m n_iter_\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1181\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     classes_ \u001b[38;5;241m=\u001b[39m enc\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes_) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1181\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1182\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1183\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1185\u001b[0m             \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1186\u001b[0m         )\n\u001b[0;32m   1188\u001b[0m     class_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(class_weight, classes\u001b[38;5;241m=\u001b[39mclasses_, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regionsStats['accuracy_2'] = np.nan\n",
    "\n",
    "for n,region in enumerate(regionsToPredict):\n",
    "    print('=========\\n')\n",
    "    currAcc = regionsStats['accuracy_0'][n]\n",
    "    currModel = regionsStats['model'][n]\n",
    "    tempTournamentId = region+currentSemesterYear\n",
    "    cut_off_var = regionsStats['cut_off_var'][n]\n",
    "    print(f'[{n+1} of {len(regionsToPredict)}] region {region} -> {currAcc}:\\n')\n",
    "    print(f'current model: {currModel}\\n')\n",
    "    \n",
    "    bestModelAbs = (regionsStats[regionsStats['region']==region])['accuracy_2'].iloc[0]\n",
    "    for model in range(len(base_models)):\n",
    "        metricModelAbs, pred = generateMetric(model, regionsTrainData[region], regionsFeatureCols[region]\n",
    "                                      , cut_off_var, tempTournamentId, currentTarget, dfToSplit, splitType)\n",
    "        if metricModelAbs<bestModelAbs or np.isnan(bestModelAbs):\n",
    "            bestModelAbs=metricModelAbs\n",
    "            bestModel=model\n",
    "        print(f'model {model} -> {metricModelAbs}')\n",
    "\n",
    "    regionsStats['model'][n] = bestModel\n",
    "    regionsStats['accuracy_2'][n] = bestModelAbs\n",
    "    \n",
    "    print(f'\\naccuracy: {bestModelAbs}')\n",
    "    print(f'best model: {bestModel}\\n')\n",
    "    \n",
    "printFinalResults(regionsStats, 'accuracy_2')\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "199030e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>accuracy_0</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>cut_off_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LPL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LCK</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultraliga</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region  model size  accuracy_0  accuracy_1  accuracy_2  cut_off_var\n",
       "0        LPL      0  NaN         NaN         NaN         NaN          1.5\n",
       "1        LCK      0  NaN         NaN         NaN         NaN          1.5\n",
       "2        PCS      0  NaN         NaN         NaN         NaN          1.5\n",
       "3        VCS      0  NaN         NaN         NaN         NaN          1.5\n",
       "4  Ultraliga      0  NaN         NaN         NaN         NaN          1.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(regionsStats['accuracy_0']))\n",
    "print(np.mean(regionsStats['accuracy_1']))\n",
    "print(np.mean(regionsStats['accuracy_2']))\n",
    "regionsStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "096c4477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>model</th>\n",
       "      <th>size</th>\n",
       "      <th>accuracy_0</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>cut_off_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LPL</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LCK</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultraliga</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region  model size  accuracy_0  accuracy_1  accuracy_2  cut_off_var\n",
       "0        LPL      0  NaN         NaN         NaN         NaN          1.5\n",
       "1        LCK      0  NaN         NaN         NaN         NaN          1.5\n",
       "2        PCS      0  NaN         NaN         NaN         NaN          1.5\n",
       "3        VCS      0  NaN         NaN         NaN         NaN          1.5\n",
       "4  Ultraliga      0  NaN         NaN         NaN         NaN          1.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(regionsStats['accuracy_0']))\n",
    "print(np.mean(regionsStats['accuracy_1']))\n",
    "print(np.mean(regionsStats['accuracy_2']))\n",
    "regionsStats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25046f8d",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94e4f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 5] region LPL -> 0.402:\n",
      "\n",
      "current var: 1.5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:15\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m, in \u001b[0;36mgenerateMetric\u001b[1;34m(model_number, regionDataListF, regionsFeatureColsF, cut_off_var, tempTournamentIdF, currentTarget, dfToSplit, splitType)\u001b[0m\n\u001b[0;32m     53\u001b[0m dfTemp, xtrain, ytrain, xtest, ytest \u001b[38;5;241m=\u001b[39m generateRegionDf(dfToSplit, regionDataListF, regionsFeatureColsF\n\u001b[0;32m     54\u001b[0m                                                         , cut_off_var, tempTournamentIdF, currentTarget, splitType)\n\u001b[0;32m     56\u001b[0m region_model \u001b[38;5;241m=\u001b[39m base_models[model_number]\n\u001b[1;32m---> 57\u001b[0m \u001b[43mregion_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m errors3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     60\u001b[0m rep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "### DROP OUTLIERS\n",
    "\n",
    "%%time\n",
    "\n",
    "# regionsFeatureCols = dict(zip(regionsList,[0]*len(regionsList)))\n",
    "# for key in regionsFeatureCols:\n",
    "#     regionsFeatureCols[key] = featureCols.copy()\n",
    "\n",
    "# for n,region in enumerate(regionsToPredict):\n",
    "#     print('=========\\n')\n",
    "#     regionFinalAcc = regionsStats['accuracy_0'][n]\n",
    "#     tempTournamentId = region+currentSemesterYear\n",
    "#     cut_off_var = regionsStats['cut_off_var'][n]\n",
    "#     region_model_number = regionsStats['model'][n]\n",
    "#     print(f'[{n+1} of {len(regionsToPredict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "#     print(f'current var: {cut_off_var}')\n",
    "#     for var in np.arange(1.0,2.0,0.1):\n",
    "        \n",
    "#         metric, pred = generateMetric(region_model_number, regionsTrainData[region], regionsFeatureCols[region]\n",
    "#                                       , var, tempTournamentId, currentTarget, dfToSplit, splitType)\n",
    "        \n",
    "#         print(f'var: {round(var,2)}, metric: {metric}')\n",
    "#         if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "#             regionFinalAcc = metric\n",
    "#             regionsStats['cut_off_var'][n] = var\n",
    "#             print(f'changed to {round(var,2)} cut-off for {metric}                                                ')\n",
    "            \n",
    "#         #print(f'[{nn+1} of {len(initialFeatures)}] testing: {feature}                        ',end='\\r')\n",
    "    \n",
    "#     regionsStats['accuracy_0'][n] = regionFinalAcc\n",
    "#     print(f'\\n\\naccuracy: {regionFinalAcc}')\n",
    "#     print(f'test data len: {len(pred)}\\n')\n",
    "    \n",
    "# printFinalResults(regionsStats, 'accuracy_0')\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c586526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
