{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07ebcb47",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed29b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "import json\n",
    "\n",
    "from Utils.constants import *\n",
    "import Utils.utils_file as utils_file\n",
    "import Utils.model_file as model_file\n",
    "\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d199165f",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c267291",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = False\n",
    "\n",
    "Utils = utils_file.Utils_Class(target='Score'\n",
    "                                ,default_model=0\n",
    "                                ,model_type='logistic'\n",
    "                                ,cache_model=cache\n",
    "                                ,cache_scraping=True)\n",
    "\n",
    "Utils.TARGET_DF = Utils.TARGET_DF[Utils.TARGET_DF[Utils.TARGET]!=2]\n",
    "\n",
    "regions_to_feed, regions_to_predict = Utils.region_lists()\n",
    "regions_to_predict = ['LCS']\n",
    "regions_to_feed = list(set(regions_to_feed + regions_to_predict))\n",
    "\n",
    "if cache:\n",
    "    regions_feature_cols = Utils.regions_feature_cols\n",
    "    regions_train_data = Utils.regions_train_data\n",
    "    regions_stats = Utils.regions_stats\n",
    "    regions_list = regions_stats['region']\n",
    "    regions_stats['train_size'] = 0\n",
    "    regions_stats['test_size'] = 0\n",
    "    regions_stats = regions_stats[regions_stats['region'].isin(regions_to_predict)].reset_index(drop=True)\n",
    "\n",
    "#regions_to_predict.remove('MSI')\n",
    "#regions_to_predict.remove('World')\n",
    "\n",
    "#regions_to_predict = ['MSI','World']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfa4dfa9",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5291e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_stats = pd.DataFrame(columns=['region','model','test_size','train_size'])\n",
    "regions_stats['region'] = regions_to_predict\n",
    "regions_list = regions_stats['region']\n",
    "regions_stats['model'] = Utils.DEFAULT_MODEL\n",
    "\n",
    "regions_train_data = dict(zip(regions_to_predict,[[x] for x in regions_to_predict]))\n",
    "regions_stats['accuracy_0'] = np.nan\n",
    "regions_stats['accuracy_1'] = np.nan\n",
    "regions_stats['accuracy_2'] = np.nan\n",
    "regions_stats['cut_off_var'] = 1.5\n",
    "\n",
    "regions_feature_cols = dict(zip(regions_list,[0]*len(regions_list)))\n",
    "for key in regions_feature_cols:\n",
    "    regions_feature_cols[key] = PLAYER_SIMPLE_FEATURE_COLS.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a78da8e3",
   "metadata": {},
   "source": [
    "### TRAIN DATA SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c23655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 1] region LCS -> nan:\n",
      "\n",
      "0.318 -> TCL added                                           \n",
      "0.235 -> Demacia added                                           \n",
      "0.233 -> Iberian added                                           \n",
      "0.23 -> LLA added                                           \n",
      "0.2 -> NLC added                                           \n",
      "0.19 -> NA_Tier2 added                                           \n",
      "0.177 -> EU added                                           \n",
      "0.169 -> LCS_Tier2 added                                           \n",
      "0.148 -> LJL added                                           \n",
      "\n",
      "len lost: 0.7%\n",
      "accuracy: 0.148\n",
      "LCS train data: ['LCS', 'TCL', 'Demacia', 'Iberian', 'LLA', 'NLC', 'NA_Tier2', 'EU', 'LCS_Tier2', 'LJL']\n",
      "len: 5917\n",
      "test data len: 214\n",
      "\n",
      "0.148\n"
     ]
    }
   ],
   "source": [
    "regions_train_data = dict(zip(regions_to_predict, [[x] for x in regions_to_predict]))\n",
    "regions_stats['accuracy_0'] = np.nan\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regions_stats['accuracy_0'][n]\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    region_model_number = regions_stats['model'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    \n",
    "    regionsToTest = [x for x in regions_to_feed]\n",
    "    regionsToTest.remove(region)\n",
    "    random.shuffle(regionsToTest)\n",
    "    for nn,regionToTest in enumerate(regionsToTest):\n",
    "        regions_train_data[region].append(regionToTest)\n",
    "        \n",
    "        metric, pred = Utils.generate_metric(region_model_number, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], region, reps=1)\n",
    "        \n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            \n",
    "            print(f'{regionFinalAcc} -> {regionToTest} added                                           ')\n",
    "        else:\n",
    "            regions_train_data[region].remove(regionToTest)\n",
    "    \n",
    "    train_len = Utils.train_len\n",
    "    regions_stats['accuracy_0'][n] = regionFinalAcc\n",
    "    regions_stats['train_size'][n] = train_len\n",
    "    regions_stats['test_size'][n] = len(pred)\n",
    "    \n",
    "    print(f'\\nlen lost: {round(Utils.len_lost,2)}%')\n",
    "    print(f'accuracy: {regionFinalAcc}')\n",
    "    print(f'{region} train data: {regions_train_data[region]}\\nlen: {train_len}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "\n",
    "mean_acc = np.mean(regions_stats['accuracy_0'])\n",
    "print(mean_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35642234",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a9c57f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 1] region LCS -> 0.148:\n",
      "\n",
      "model: 0\n",
      "DMG% removed for 0.143                                                \n",
      "\n",
      "\n",
      "len lost: 0.74%\n",
      "accuracy: 0.143\n",
      "LCS feature count: 21\n",
      "test data len: 214\n",
      "\n",
      "5759.0\n",
      "0.143\n"
     ]
    }
   ],
   "source": [
    "regions_stats['accuracy_1'] = np.nan\n",
    "for key in regions_list:\n",
    "    regions_feature_cols[key] = PLAYER_SIMPLE_FEATURE_COLS.copy()\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    regionFinalAcc = regions_stats['accuracy_0'][n]\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    region_model_number = regions_stats['model'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {regionFinalAcc}:\\n')\n",
    "    print(f'model: {region_model_number}')\n",
    "    \n",
    "    initialFeatures = regions_feature_cols[region].copy()\n",
    "    for nn,feature in enumerate(initialFeatures):\n",
    "        regions_feature_cols[region].remove(feature)\n",
    "        \n",
    "        metric, pred = Utils.generate_metric(region_model_number, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], region, reps=1)\n",
    "        \n",
    "        if metric < regionFinalAcc or np.isnan(regionFinalAcc):\n",
    "            regionFinalAcc = metric\n",
    "            print(f'{feature} removed for {metric}                                                ')\n",
    "        else:\n",
    "            regions_feature_cols[region].append(feature)\n",
    "    \n",
    "    train_len = Utils.train_len\n",
    "    regions_stats['accuracy_1'][n] = regionFinalAcc\n",
    "    regions_stats['train_size'][n] = train_len\n",
    "\n",
    "    print(f'\\n\\nlen lost: {round(Utils.len_lost,2)}%')\n",
    "    print(f'accuracy: {regionFinalAcc}')\n",
    "    print(f'{region} feature count: {len(regions_feature_cols[region])}')\n",
    "    print(f'test data len: {len(pred)}\\n')\n",
    "    \n",
    "mean_acc = np.mean(regions_stats['accuracy_1'])\n",
    "mean_train = np.mean(regions_stats['train_size'])\n",
    "\n",
    "print(mean_train)\n",
    "print(mean_acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18c01c99",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd7a21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "\n",
      "[1 of 1] region LCS -> 0.148:\n",
      "\n",
      "current model: 0\n",
      "\n",
      "model 0 -> 0.143\n",
      "\n",
      "len lost: 0.74%\n",
      "accuracy: 0.143\n",
      "best model: 0\n",
      "\n",
      "0.143\n",
      "5759.0\n"
     ]
    }
   ],
   "source": [
    "regions_stats['accuracy_2'] = np.nan\n",
    "\n",
    "##########\n",
    "\n",
    "for n,region in enumerate(regions_to_predict):\n",
    "    print('=========\\n')\n",
    "    currAcc = regions_stats['accuracy_0'][n]\n",
    "    currModel = regions_stats['model'][n]\n",
    "    cut_off_var = regions_stats['cut_off_var'][n]\n",
    "    print(f'[{n+1} of {len(regions_to_predict)}] region {region} -> {currAcc}:\\n')\n",
    "    print(f'current model: {currModel}\\n')\n",
    "    \n",
    "    bestModelAbs = (regions_stats[regions_stats['region']==region])['accuracy_2'].iloc[0]\n",
    "    for model in range(len(Utils.BASE_MODELS)):\n",
    "        metric, pred = Utils.generate_metric(model, regions_feature_cols[region]\n",
    "                                             , regions_train_data[region], region, reps=5)\n",
    "        if metric < bestModelAbs or np.isnan(bestModelAbs):\n",
    "            bestModelAbs = metric\n",
    "            bestModel = model\n",
    "        print(f'model {model} -> {metric}')\n",
    "\n",
    "    train_len = Utils.train_len\n",
    "    regions_stats['train_size'][n] = train_len\n",
    "    regions_stats['model'][n] = bestModel\n",
    "    regions_stats['accuracy_2'][n] = bestModelAbs\n",
    "    \n",
    "    print(f'\\nlen lost: {round(Utils.len_lost,2)}%')\n",
    "    print(f'accuracy: {bestModelAbs}')\n",
    "    print(f'best model: {bestModel}\\n')\n",
    "    \n",
    "mean_acc = np.mean(regions_stats['accuracy_2'])\n",
    "print(mean_acc)\n",
    "mean_train = np.mean(regions_stats['train_size'])\n",
    "print(mean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e6427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.148\n",
      "0.143\n",
      "0.143\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>model</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_size</th>\n",
       "      <th>accuracy_0</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>cut_off_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LCS</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>5759</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region  model test_size train_size  accuracy_0  accuracy_1  accuracy_2  \\\n",
       "0    LCS      0       214       5759       0.148       0.143       0.143   \n",
       "\n",
       "   cut_off_var  \n",
       "0          1.5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(regions_stats['accuracy_0']))\n",
    "print(np.mean(regions_stats['accuracy_1']))\n",
    "print(np.mean(regions_stats['accuracy_2']))\n",
    "regions_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23641b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.148\n",
      "0.143\n",
      "0.143\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>model</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_size</th>\n",
       "      <th>accuracy_0</th>\n",
       "      <th>accuracy_1</th>\n",
       "      <th>accuracy_2</th>\n",
       "      <th>cut_off_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LCS</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>5759</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region  model test_size train_size  accuracy_0  accuracy_1  accuracy_2  \\\n",
       "0    LCS      0       214       5759       0.148       0.143       0.143   \n",
       "\n",
       "   cut_off_var  \n",
       "0          1.5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(regions_stats['accuracy_0']))\n",
    "print(np.mean(regions_stats['accuracy_1']))\n",
    "print(np.mean(regions_stats['accuracy_2']))\n",
    "regions_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0f194c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'20231'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m regions_cache \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m----> 2\u001b[0m regions_cache[CURRENT_YEAR_SEMESTER][\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m regions_feature_cols\n\u001b[0;32m      3\u001b[0m regions_cache[CURRENT_YEAR_SEMESTER][\u001b[39m'\u001b[39m\u001b[39mtrain_data\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m regions_train_data\n\u001b[0;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mData/raw_data/regions_cache.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fp:\n",
      "\u001b[1;31mKeyError\u001b[0m: '20231'"
     ]
    }
   ],
   "source": [
    "regions_cache = dict()\n",
    "regions_cache[tuple(CURRENT_YEAR_SEMESTER, 'features', 'logistic')] = regions_feature_cols\n",
    "regions_cache[tuple(CURRENT_YEAR_SEMESTER, 'train_data', 'logistic')] = regions_train_data\n",
    "\n",
    "with open(f'Data/raw_data/regions_cache.json', 'w') as fp:\n",
    "    json.dump(regions_cache, fp)\n",
    "\n",
    "regions_stats.to_pickle(\"Data/raw_data/regions_stats.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25046f8d",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c586526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
